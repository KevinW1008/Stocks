import datetime as dt

import numpy as np

import matplotlib.pyplot as plt
from matplotlib import style

import pandas as pd
import pandas_datareader.data as web
from pandas_datareader._utils import RemoteDataError
from pandas.plotting import scatter_matrix

from sklearn import preprocessing, svm
import sklearn.model_selection as sk
from sklearn.linear_model import LinearRegression


import math
#############################################################################

style.use("ggplot")
start = dt.datetime(2015, 1, 1)
end = dt.datetime.now()

def linear_Single_Model(ticker):
    
    #Aquiring data from a company as.csv
    df = web.DataReader(ticker, "yahoo", start, end)
    df.to_csv("%s.csv" % ticker)
    df = pd.read_csv("%s.csv" % ticker, parse_dates = True, index_col = 0 )

    df["100ma"] = df["Adj Close"].rolling(window = 100, min_periods = 0).mean()

    plt.figure(figsize= (15,15))
    # plt.plot(df.index, df['Adj Close'], label ="%s Adj Close" % ticker)
    # plt.plot(df.index, df['100ma'], label ="%s 100 Rolling Avg" % ticker)
    plt.ylabel("Stock Value/Prices")
    plt.xlabel("Year")

    adj_close= df["Adj Close"]
    expected_return = (adj_close / adj_close.shift(1)) - 1 

    plt.plot(df.index, expected_return, label ="exp_return")

    plt.legend()
    plt.show()

def Scatter_Corr_Model():
    dfcomp = web.DataReader(['AAPL', 'GE', 'GOOG', 'IBM', 'MSFT'], 'yahoo', start=start, end=end)['Adj Close']
    dfcomp.to_csv("dfcomp.csv")
    dfcomp = pd.read_csv("dfcomp.csv", parse_dates = True, index_col = 0 )

    #helps calculate percent change
    pct_df = dfcomp.pct_change()
    #calculating correlations between the percent changes of returns
    #for the companies that we listed
    corr = pct_df.corr()
    plt.figure(figsize= (15,15))
    plt.scatter(pct_df.AAPL, pct_df.GE)
    plt.xlabel("Returns AAPL")
    plt.ylabel("Returns GE")

    scatter_matrix(pct_df, diagonal='kde', figsize=(10, 10));

def Heat_Map():
    dfcomp = web.DataReader(['AAPL', 'GE', 'GOOG', 'IBM', 'MSFT'], 'yahoo', start=start, end=end)['Adj Close']
    dfcomp.to_csv("dfcomp.csv")
    dfcomp = pd.read_csv("dfcomp.csv", parse_dates = True, index_col = 0 )

    #helps calculate percent change
    pct_df = dfcomp.pct_change()
    #calculating correlations between the percent changes of returns
    #for the companies that we listed
    corr = pct_df.corr()

    plt.imshow(corr, cmap='hot', interpolation='none')
    plt.colorbar()
    plt.xticks(range(len(corr)), corr.columns)
    plt.yticks(range(len(corr)), corr.columns);

    plt.legend()
    plt.show()

def Risk_Return():
    # Apart from correlation, we also analyse each stockâ€™s risks and returns. 
    # In this case we are extracting the average of returns (Return Rate) and the standard deviation of returns (Risk).

    dfcomp = web.DataReader(['AAPL', 'GE', 'GOOG', 'IBM', 'MSFT'], 'yahoo', start=start, end=end)['Adj Close']
    dfcomp.to_csv("dfcomp.csv")
    dfcomp = pd.read_csv("dfcomp.csv", parse_dates = True, index_col = 0 )
    #helps calculate percent change
    pct_df = dfcomp.pct_change()

    plt.scatter(pct_df.mean(), pct_df.std())
    plt.xlabel('Expected returns')
    plt.ylabel('Risk')
    for label, x, y in zip(pct_df.columns, pct_df.mean(), pct_df.std()):
        plt.annotate(
        label, 
        xy = (x, y), xytext = (20, -20),
        textcoords = 'offset points', ha = 'right', va = 'bottom',
        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),
        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))
    plt.show()

#Comparing actual data to a model that predicts those values
def Predicting_PriceV1(ticker): 
    
    df = web.DataReader(ticker, "yahoo", start, end)
    dfog= df
    
    #Volatilty of the market are better values for prediciton
    df['HL_PCT'] = (df['High'] - df['Low']) / df['Low'] * 100.0
    df['PCT_change'] = (df['Close'] - df['Open']) / df['Open'] * 100.0

    df = df[['Adj Close', 'HL_PCT', 'PCT_change', 'Volume']]

    #We are forecasting Adjusted Closing Price
    forecast_col = 'Adj Close'
    #Fill any empty columns with -99999 as good practice
    df.fillna(value=-99999, inplace=True)
    #How many days we want to forecast out, lets do 1 percent of the data
    forecast_out = int(.01 * math.ceil(len(df)))

    #new calumn in df that contains shifted values up 
    #Label contains a percentage of training data
    df['label'] = df[forecast_col].shift(-forecast_out)
  

    X = np.array(df.drop(['label'], 1))

    #Shifts the range of the values of -1 to 1
    X = preprocessing.scale(X)
    #Contains data points after forecast_out point
    X_lately = X[-forecast_out:]
    #Contains data points before forecast_out point
    X = X[:-forecast_out]
    df.dropna(inplace=True)
    y = np.array(df['label'])
    
    X_train, X_test, y_train, y_test = sk.train_test_split(X, y, test_size=0.5)

    #n_jobs=-1 ensures the CPU will use all available threads to process
    clf = LinearRegression(n_jobs=-1)
    #This will traing our data
    clf.fit(X_train, y_train)
    confidence = clf.score(X_test, y_test)


    forecast_set = clf.predict(X_lately)
    df['Forecast'] = np.nan


    last_date = df.iloc[-1].name
    last_unix = last_date.timestamp()
    one_day = 86400
    next_unix = last_unix + one_day

    for i in forecast_set:
        next_date = dt.datetime.fromtimestamp(next_unix)
        next_unix += 86400
        df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)]+[i]

    df.to_csv("%s.csv" % ticker)

    print('Our linear regression model computes a beta coefficient (slope) of:')
    print(clf.coef_[0].round())
    print('Tomorrow prices is thus to be predicted as:')
    print((clf.coef_[0] + dfog['Adj Close'][-1]).round())


    plt.plot(dfog['Adj Close'])
    plt.plot(df['Forecast'])
    plt.legend(loc=4)
    plt.title('%s\'s Adjusted Close History and Prediction Model' % ticker)
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.show()


Predicting_PriceV1("TSLA")
